{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Simple Variational AutoEncoder training and inference CIFAR10 example\n",
    "\n",
    "**Description**: in this notebook, we showcase the training process and inference capabilities of a simple variational auto-encoder model on the CIFAR10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports, definitions and setup\n",
    "\n",
    "The first block is needed only when the current environment doesn't have the `dlproject` package installed.\n",
    "Therefore, if you already cloned the whole repository and run the `pip install -e .` command, you can skip the first block.\n",
    "\n",
    "If you're running this notebook only on a Jupyter server, run the first block as well in order to obtain the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/peiva-git/deep_learning_project.git\n",
    "%cd deep_learning_project\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dlproject as dlp\n",
    "import tensorflow as tf\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the CIFAR10 dataset\n",
    "\n",
    "The CIFAR10 dataset contains 50000 32x32 color images in the training set and 10000 images in the testing set, labeled over 10 categories.\n",
    "\n",
    "In order to use the images on this simple model, they're converted to grayscale 32x32 images in the pre-processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_builder = dlp.data.CIFAR10DatasetBuilder()\n",
    "dataset_builder.preprocess_dataset_simple_vae()\n",
    "train_x, test_x = dataset_builder.train_x, dataset_builder.test_x\n",
    "train_y, test_y = dataset_builder.train_y, dataset_builder.test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "simple_vae = dlp.models.SimpleVAE(input_dim=32 * 32, latent_dim=2)\n",
    "vae = simple_vae.vae\n",
    "encoder = simple_vae.encoder\n",
    "decoder = simple_vae.decoder\n",
    "vae.compile(optimizer=tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Train the instantiated model on the CIFAR10 dataset.\n",
    "\n",
    "This block also saves a backup and a checkpoint every 20 epochs, so that you can automatically resume the training if it gets interrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_cifar10')):\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_cifar10', 'backup'))\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_cifar10', 'model_checkpoints'))\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_cifar10', 'tensorboard_logs'))\n",
    "\n",
    "model_dir_path = os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_cifar10')\n",
    "\n",
    "vae.fit(\n",
    "    train_x, train_x,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(test_x, test_x),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.BackupAndRestore(\n",
    "            backup_dir=os.path.join(model_dir_path, 'backup'),\n",
    "            save_freq=31260 # 20 * 1563, each 20 epochs\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(os.path.join(model_dir_path, 'model_checkpoints'), save_freq=31260),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=os.path.join(model_dir_path, 'tensorboard_logs'))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Save the trained model\n",
    "\n",
    "Save the trained model's weights for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(), 'output', 'models')):\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'output', 'models'))\n",
    "\n",
    "vae.save_weights(os.path.join(os.getcwd(), 'output', 'models', f'{vae.name}_weights_cifar10.keras'))\n",
    "encoder.save_weights(os.path.join(os.getcwd(), 'output', 'models', f'{encoder.name}_weights_cifar10.keras'))\n",
    "decoder.save_weights(os.path.join(os.getcwd(), 'output', 'models', f'{decoder.name}_weights_cifar10.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the model\n",
    "\n",
    "Instead of training the model, you can load its weights from a previously saved `.keras` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vae.load_weights(os.path.join(os.getcwd(), 'models', f'{vae.name}_weights_cifar10.keras'))\n",
    "encoder.load_weights(os.path.join(os.getcwd(), 'models', f'{encoder.name}_weights_cifar10.keras'))\n",
    "decoder.load_weights(os.path.join(os.getcwd(), 'models', f'{decoder.name}_weights_cifar10.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualization\n",
    "\n",
    "Display a scatter plot of the encoded test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dlp.data.show_encoder_scatter_plot(test_x, test_y, encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Display artificially generated images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dlp.data.show_latent_plane_sampled_points(decoder, (-1, 1), (-1, 1), number_of_figures=15, figure_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Metrics\n",
    "\n",
    "Compute the PSNR and the SSIM metrics for the trained VAE model, between the original testing images and the reconstructed images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reconstructed_images = vae.predict(test_x)\n",
    "print(dlp.evaluation.compute_mean_psnr(test_x, reconstructed_images))\n",
    "print(dlp.evaluation.compute_mean_ssim(test_x, reconstructed_images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
