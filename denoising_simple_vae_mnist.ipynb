{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Simple Variational AutoEncoder training and inference on noisy MNIST dataset\n",
    "\n",
    "**Description**: in this notebook, we showcase the training process and inference capabilities of a simple variational auto-encoder model on the MNIST dataset.\n",
    "The model is trained to reconstruct noisy images.\n",
    "The noisy images are built from MNIST images, with added random noise."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports, definitions and setup\n",
    "\n",
    "The first block is needed only when the current environment doesn't have the `dlproject` package installed.\n",
    "Therefore, if you already cloned the whole repository and run the `pip install -e .` command, you can skip the first block.\n",
    "\n",
    "If you're running this notebook only on a Jupyter server, run the first block as well in order to obtain the necessary dependencies."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/peiva-git/deep_learning_project.git\n",
    "%cd deep_learning_project\n",
    "!pip install -e ."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import dlproject as dlp\n",
    "import tensorflow as tf\n",
    "\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the MNIST dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_builder = dlp.data.MNISTDatasetBuilder()\n",
    "dataset_builder.preprocess_dataset_simple_vae(noise_factor=0.4)\n",
    "train_x, test_x = dataset_builder.train_x, dataset_builder.test_x\n",
    "train_y, test_y = dataset_builder.train_y, dataset_builder.test_y\n",
    "noisy_train_data, noisy_test_data = dataset_builder.noisy_train_data, dataset_builder.noisy_test_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "simple_vae = dlp.models.SimpleVAE(input_dim=28 * 28, latent_dim=2)\n",
    "vae = simple_vae.vae\n",
    "encoder = simple_vae.encoder\n",
    "decoder = simple_vae.decoder\n",
    "vae.compile(optimizer='adam')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model\n",
    "\n",
    "Train the instantiated model on the MNIST dataset.\n",
    "\n",
    "This block also saves a backup and a checkpoint every 20 epochs, so that you can automatically resume the training if it gets interrupted."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_noisy_mnist')):\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_noisy_mnist', 'backup'))\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_noisy_mnist', 'model_checkpoints'))\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_noisy_mnist', 'tensorboard_logs'))\n",
    "\n",
    "model_dir_path = os.path.join(os.getcwd(), 'output', 'training-callback-results', f'{vae.name}_noisy_mnist')\n",
    "\n",
    "vae.fit(\n",
    "    noisy_train_data, train_x,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(noisy_test_data, test_x),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.BackupAndRestore(\n",
    "            backup_dir=os.path.join(model_dir_path, 'backup'),\n",
    "            save_freq=37500 # 20 * 1875, each 20 epochs\n",
    "        ),\n",
    "        tf.keras.callbacks.ModelCheckpoint(os.path.join(model_dir_path, 'model_checkpoints'), save_freq=37500),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=os.path.join(model_dir_path, 'tensorboard_logs'))\n",
    "    ]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save the trained model\n",
    "\n",
    "Save the just trained model for later use."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(os.getcwd(), 'output', 'models')):\n",
    "    os.makedirs(os.path.join(os.getcwd(), 'output', 'models'))\n",
    "\n",
    "vae.save_weights(os.path.join(os.getcwd(), 'output', 'models', f'{vae.name}_weights_noisy_mnist.keras'))\n",
    "encoder.save_weights(os.path.join(os.getcwd(), 'output', 'models', f'{encoder.name}_weights_noisy_mnist.keras'))\n",
    "decoder.save_weights(os.path.join(os.getcwd(), 'output', 'models', f'{decoder.name}_weights_noisy_mnist.keras'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the model\n",
    "\n",
    "Instead of training the model, you can load its weights from a previously saved `.keras` file."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vae.load_weights(os.path.join(os.getcwd(), 'models', f'{vae.name}_weights_noisy_mnist.keras'))\n",
    "encoder.load_weights(os.path.join(os.getcwd(), 'models', f'{encoder.name}_weights_noisy_mnist.keras'))\n",
    "decoder.load_weights(os.path.join(os.getcwd(), 'models', f'{decoder.name}_weights_noisy_mnist.keras'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization\n",
    "\n",
    "Display a scatter plot of the encoded test data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dlp.data.show_encoder_scatter_plot(noisy_test_data, test_y, encoder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display artificially generated digits."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dlp.data.show_latent_plane_sampled_points(decoder, (-1, 1), (-1, 1), number_of_figures=15, figure_size=28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Metrics\n",
    "\n",
    "Compute the PSNR and the SSIM metrics for the trained VAE model, between the original testing images and the reconstructed images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reconstructed_images = vae.predict(noisy_test_data)\n",
    "print(dlp.evaluation.compute_mean_psnr(test_x, reconstructed_images))\n",
    "print(dlp.evaluation.compute_mean_ssim(test_x, reconstructed_images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}