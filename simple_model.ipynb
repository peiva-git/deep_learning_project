{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true,
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "# Simple AutoEncoder training and inference example\n",
    "\n",
    "**Description**: in this notebook, we showcase the training process and inference capabilities of a simple autoencoder model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports, definitions and setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "X3EkwOQTcZTV"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git clone https://github.com/peiva-git/deep_learning_project.git\n",
    "%cd deep_learning_project\n",
    "!pip install -e ."
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Fi8roD-YcZTg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import dlproject as dlp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os.path"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "9S1e8RlycZTk"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load the MNIST dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "1jSFLq28cZTl"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_jjq3Vb1mtU"
   },
   "outputs": [],
   "source": [
    "dataset_builder = dlp.data.MNISTDatasetBuilder()\n",
    "dataset_builder.preprocess_dataset()\n",
    "train_data, test_data = dataset_builder.train_data, dataset_builder.test_data\n",
    "noisy_train_data, noisy_test_data = dataset_builder.noisy_train_data, dataset_builder.noisy_test_data"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, n + 1):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(noisy_train_data[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "d9YWwj6Di7Ww"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Instantiate the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "n3DBq4HEcZTm"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "autoencoder = dlp.models.SimpleAutoencoder(input_shape=(28, 28, 1))\n",
    "autoencoder.model.compile(optimizer='adam', loss='binary_crossentropy')"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "Kqtn7L-fcZTn"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model\n",
    "\n",
    "### Testing the model\n",
    "\n",
    "First, we train the model to reconstruct the image that's given as an input. The reconstructed images should be similar, but not exactly the same.\n",
    "We also save the model for later use."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "pr5x1LppcZTo"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder.model.fit(\n",
    "    x=train_data,\n",
    "    y=train_data,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(test_data, test_data)\n",
    ")\n",
    "\n",
    "autoencoder.model.save(os.path.join('output', 'models', autoencoder.model.name + '.keras'))"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "1Q4gA0X4cZTq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Display the results."
   ],
   "metadata": {
    "id": "3NdwKKBYq-tn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "decoded_imgs = autoencoder.model.predict(test_data)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, n + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i)\n",
    "    plt.imshow(test_data[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "BEaaa4qHiLAf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Denoise images\n",
    "\n",
    "Secondly, we retrain the model to reconstruct the image from a noisy input."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    },
    "id": "e9fqC677cZTr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "autoencoder.model.fit(\n",
    "    x=noisy_train_data,\n",
    "    y=train_data,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(noisy_test_data, test_data)\n",
    ")"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "id": "4vFCM3wXcZTs"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's take a look at the results. Top, the ground truth digits fed to the network, than the noisy version and finally the digits are reconstructed by the network. It seems to work pretty well."
   ],
   "metadata": {
    "id": "3YM4QRuxovdn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def display_random_images(test_data, noisy_test_data, autoencoder_model, num_images=10):\n",
    "    # Randomly select 10 indices from the test dataset\n",
    "    random_indices = random.sample(range(len(test_data)), num_images)\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        # Original clean image\n",
    "        plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(test_data[idx].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Noisy image\n",
    "        plt.subplot(3, num_images, num_images + i + 1)\n",
    "        plt.imshow(noisy_test_data[idx].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Predicted output from the autoencoder\n",
    "        predicted_output = autoencoder_model.predict(noisy_test_data[idx].reshape(1, 28, 28, 1))\n",
    "        plt.subplot(3, num_images, 2 * num_images + i + 1)\n",
    "        plt.imshow(predicted_output[0].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "display_random_images(test_data, noisy_test_data, autoencoder.model)\n"
   ],
   "metadata": {
    "id": "124Y8PmglfBk"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}