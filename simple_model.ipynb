{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports, definitions and setup"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "X3EkwOQTcZTV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "!git clone https://github.com/peiva-git/deep_learning_project.git\n",
        "%cd deep_learning_project\n",
        "!pip install -e ."
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Fi8roD-YcZTg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [],
      "source": [
        "import dlproject as dlp\n",
        "import matplotlib.pyplot as plt\n",
        "import os.path"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9S1e8RlycZTk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the MNIST dataset"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "1jSFLq28cZTl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "M_jjq3Vb1mtU"
      },
      "outputs": [],
      "source": [
        "dataset_builder = dlp.data.MNISTDatasetBuilder()\n",
        "dataset_builder.preprocess_dataset_simple_ae(0.7)\n",
        "train_data, test_data = dataset_builder.train_x, dataset_builder.test_x\n",
        "noisy_train_data, noisy_test_data = dataset_builder.noisy_train_data, dataset_builder.noisy_test_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_previews = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(1, number_of_previews + 1):\n",
        "    ax = plt.subplot(1, number_of_previews, i)\n",
        "    plt.imshow(noisy_train_data[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "d9YWwj6Di7Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate the model"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "n3DBq4HEcZTm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [],
      "source": [
        "autoencoder_mnist = dlp.models.SimpleAutoencoder(input_shape=(28, 28, 1))\n",
        "autoencoder_mnist.model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model = autoencoder_mnist.model"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Kqtn7L-fcZTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "### Testing the model\n",
        "\n",
        "First, we train the model to reconstruct the image that's given as an input. The reconstructed images should be similar, but not exactly the same.\n",
        "We also save the model for later use."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "pr5x1LppcZTo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model.fit(\n",
        "    x=train_data,\n",
        "    y=train_data,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        "    validation_data=(test_data, test_data)\n",
        ")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1Q4gA0X4cZTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display the results."
      ],
      "metadata": {
        "id": "3NdwKKBYq-tn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = model.predict(test_data)\n",
        "\n",
        "number_of_previews = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, number_of_previews + 1):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, number_of_previews, i)\n",
        "    plt.imshow(test_data[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, number_of_previews, i + number_of_previews)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "BEaaa4qHiLAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Denoise images\n",
        "\n",
        "Secondly, we retrain the model to reconstruct the image from a noisy input."
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "e9fqC677cZTr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "from tensorflow.keras.saving import load_model\n",
        "\n",
        "if os.path.exists(os.path.join(os.getcwd(), 'models', f'{model.name}_mnist.keras')):\n",
        "  model_path = os.path.join(os.getcwd(), 'models', f'{model.name}_mnist.keras')\n",
        "  model = load_model(model_path)\n",
        "else:\n",
        "  if not os.path.exists(os.path.join(os.getcwd(), 'models')):\n",
        "    os.mkdir(os.path.join(os.getcwd(), 'models'))\n",
        "\n",
        "  model.fit(\n",
        "      x=noisy_train_data,\n",
        "      y=train_data,\n",
        "      epochs=100,\n",
        "      batch_size=128,\n",
        "      shuffle=True,\n",
        "      validation_data=(noisy_test_data, test_data)\n",
        "  )\n",
        "\n",
        "model.save(os.path.join('models', f'{model.name}_mnist.keras'))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "4vFCM3wXcZTs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at the results. Top, the ground truth digits fed to the network, than the noisy version and finally the digits are reconstructed by the network. It seems to work pretty well."
      ],
      "metadata": {
        "id": "3YM4QRuxovdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def display_random_images(test_data, noisy_test_data, model, num_images=10):\n",
        "    # Randomly select 10 indices from the test dataset\n",
        "    random_indices = random.sample(range(len(test_data)), num_images)\n",
        "\n",
        "    plt.figure(figsize=(15, 4))\n",
        "\n",
        "    for i, idx in enumerate(random_indices):\n",
        "        # Original clean image\n",
        "        plt.subplot(3, num_images, i + 1)\n",
        "        plt.imshow(test_data[idx].reshape(28, 28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Noisy image\n",
        "        plt.subplot(3, num_images, num_images + i + 1)\n",
        "        plt.imshow(noisy_test_data[idx].reshape(28, 28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Predicted output from the autoencoder\n",
        "        predicted_output = model.predict(noisy_test_data[idx].reshape(1, 28, 28, 1))\n",
        "        plt.subplot(3, num_images, 2 * num_images + i + 1)\n",
        "        plt.imshow(predicted_output[0].reshape(28, 28), cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "display_random_images(test_data, noisy_test_data, model)\n"
      ],
      "metadata": {
        "id": "124Y8PmglfBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model with CIFAR10 dataset"
      ],
      "metadata": {
        "id": "1r9m6jezt8Fj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the CIFAR10 dataset"
      ],
      "metadata": {
        "id": "U9aHipb0GHos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_builder = dlp.data.CIFAR10DatasetBuilder()\n",
        "dataset_builder.preprocess_dataset(0.1)\n",
        "train_data, test_data = dataset_builder.train_data, dataset_builder.test_data\n",
        "noisy_train_data, noisy_test_data = dataset_builder.noisy_train_data, dataset_builder.noisy_test_data"
      ],
      "metadata": {
        "id": "U-zP2ceouChX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def display_random_images(train_data, noisy_train_data, num_images=8):\n",
        "    fig, axes = plt.subplots(2, num_images, figsize=(16, 4))\n",
        "\n",
        "    for i in range(num_images):\n",
        "        index = random.randint(0, train_data.shape[0] - 1)\n",
        "\n",
        "        # Display a random image from the clean dataset\n",
        "        axes[0, i].imshow(train_data[index])\n",
        "        axes[0, i].set_title(\"Clean\")\n",
        "\n",
        "        # Display the corresponding image from the noisy dataset\n",
        "        axes[1, i].imshow(noisy_train_data[index])\n",
        "        axes[1, i].set_title(\"Noisy\")\n",
        "\n",
        "        # Remove axis labels\n",
        "        axes[0, i].axis('off')\n",
        "        axes[1, i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Display 8 random images from the datasets\n",
        "display_random_images(train_data, noisy_train_data, num_images=8)\n"
      ],
      "metadata": {
        "id": "zt_eCJ3ty_DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Istantiate the model for CIFAR10 dataset"
      ],
      "metadata": {
        "id": "pJNsMBZTFLhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder_cifar = dlp.models.SimpleAutoencoder(input_shape=(32, 32, 3))\n",
        "autoencoder_cifar.model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model = autoencoder_cifar.model"
      ],
      "metadata": {
        "id": "7DAcBZWw2zlh"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the CIFAR10 model\n",
        "\n"
      ],
      "metadata": {
        "id": "bE2MTxR2FYCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.saving import load_model\n",
        "\n",
        "if os.path.exists(os.path.join(os.getcwd(), 'models', f'{model.name}_cifar.keras')):\n",
        "  model_path = os.path.join(os.getcwd(), 'models', f'{model.name}_cifar.keras')\n",
        "  model = load_model(model_path)\n",
        "else:\n",
        "  if not os.path.exists(os.path.join(os.getcwd(), 'models')):\n",
        "    os.mkdir(os.path.join(os.getcwd(), 'models'))\n",
        "\n",
        "  model.fit(\n",
        "      x=noisy_train_data,\n",
        "      y=train_data,\n",
        "      epochs=100,\n",
        "      batch_size=128,\n",
        "      shuffle=True,\n",
        "      validation_data=(noisy_test_data, test_data)\n",
        "  )\n",
        "  autoencoder_cifar.model.save(os.path.join(os.getcwd(), 'models', f'{model.name}_cifar.keras'))"
      ],
      "metadata": {
        "id": "ZnDhpmjlJEGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_random_images(test_data, noisy_test_data, autoencoder, num_images=10):\n",
        "    # Randomly select 10 indices from the test dataset\n",
        "    random_indices = random.sample(range(len(test_data)), num_images)\n",
        "\n",
        "    plt.figure(figsize=(15, 4))\n",
        "\n",
        "    for i, idx in enumerate(random_indices):\n",
        "        # Original clean image\n",
        "        plt.subplot(3, num_images, i + 1)\n",
        "        plt.imshow(test_data[idx])\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Noisy image\n",
        "        plt.subplot(3, num_images, num_images + i + 1)\n",
        "        plt.imshow(noisy_test_data[idx])\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Predicted output from the autoencoder\n",
        "        predicted_output = model.predict(noisy_test_data[idx].reshape(1, 32, 32, 3))\n",
        "        plt.subplot(3, num_images, 2 * num_images + i + 1)\n",
        "        plt.imshow(predicted_output[0])\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "display_random_images(test_data, noisy_test_data, model, num_images=10)\n"
      ],
      "metadata": {
        "id": "hquMd2cQBcar"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}