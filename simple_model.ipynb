{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "X3EkwOQTcZTV",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports, definitions and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fi8roD-YcZTg",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/peiva-git/deep_learning_project.git\n",
    "%cd deep_learning_project\n",
    "!pip install -e .\n",
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9S1e8RlycZTk",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dlproject as dlp\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "1jSFLq28cZTl",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ru_EIKwR0bIV"
   },
   "outputs": [],
   "source": [
    "# Uncomment one line to select the desired noise level\n",
    "\n",
    "noise_level = 'high'\n",
    "# noise_level = 'med'\n",
    "# noise_level = 'low'\n",
    "\n",
    "if noise_level == 'high':\n",
    "  noise_value = 0.7\n",
    "elif noise_level == 'med':\n",
    "  noise_value = 0.4\n",
    "elif noise_level == 'low':\n",
    "  noise_value = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_jjq3Vb1mtU"
   },
   "outputs": [],
   "source": [
    "dataset_builder = dlp.data.MNISTDatasetBuilder()\n",
    "dataset_builder.preprocess_dataset_simple_ae(noise_value)\n",
    "train_data, test_data = dataset_builder.train_x, dataset_builder.test_x\n",
    "noisy_train_data, noisy_test_data = dataset_builder.noisy_train_data, dataset_builder.noisy_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d9YWwj6Di7Ww"
   },
   "outputs": [],
   "source": [
    "number_of_previews = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1, number_of_previews + 1):\n",
    "    ax = plt.subplot(1, number_of_previews, i)\n",
    "    plt.imshow(noisy_train_data[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "n3DBq4HEcZTm",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Instantiate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kqtn7L-fcZTn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "autoencoder_mnist = dlp.models.SimpleAutoencoder(input_shape=(28, 28, 1))\n",
    "autoencoder_mnist.model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model = autoencoder_mnist.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "pr5x1LppcZTo",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train the model\n",
    "\n",
    "### Testing the model\n",
    "\n",
    "First, we train the model to reconstruct the image that's given as an input. The reconstructed images should be similar, but not exactly the same.\n",
    "We also save the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Q4gA0X4cZTq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    x=train_data,\n",
    "    y=train_data,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(test_data, test_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NdwKKBYq-tn"
   },
   "source": [
    "Display the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEaaa4qHiLAf"
   },
   "outputs": [],
   "source": [
    "decoded_imgs = model.predict(test_data)\n",
    "\n",
    "number_of_previews = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(1, number_of_previews + 1):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, number_of_previews, i)\n",
    "    plt.imshow(test_data[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, number_of_previews, i + number_of_previews)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "e9fqC677cZTr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Denoise images\n",
    "\n",
    "Secondly, we retrain the model to reconstruct the image from a noisy input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aPN4Msxu1-w7",
    "outputId": "39a7788d-cf81-4613-878a-f9b40b703e02"
   },
   "outputs": [],
   "source": [
    "print(os.path.join(os.getcwd(), 'models', f'{model.name}_mnist_{noise_level}.keras'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vFCM3wXcZTs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.saving import load_model\n",
    "\n",
    "model_path = os.path.join(os.getcwd(), 'models',\n",
    "                               f'{model.name}_mnist_{noise_level}_noise.keras')\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "  model = load_model(model_path)\n",
    "else:\n",
    "  if not os.path.exists(os.path.join(os.getcwd(), 'models')):\n",
    "    os.mkdir(os.path.join(os.getcwd(), 'models'))\n",
    "\n",
    "  model.fit(\n",
    "      x=noisy_train_data,\n",
    "      y=train_data,\n",
    "      epochs=100,\n",
    "      batch_size=128,\n",
    "      shuffle=True,\n",
    "      validation_data=(noisy_test_data, test_data)\n",
    "  )\n",
    "\n",
    "model.save(os.path.join('models', f'{model.name}_mnist_{noise_level}_noise.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YM4QRuxovdn"
   },
   "source": [
    "Let's take a look at the results. Top, the ground truth digits fed to the network, than the noisy version and finally the digits are reconstructed by the network. It seems to work pretty well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "124Y8PmglfBk"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def display_random_images(test_data, noisy_test_data, model, num_images=10):\n",
    "    # Randomly select 10 indices from the test dataset\n",
    "    random_indices = random.sample(range(len(test_data)), num_images)\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        # Original clean image\n",
    "        plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(test_data[idx].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Noisy image\n",
    "        plt.subplot(3, num_images, num_images + i + 1)\n",
    "        plt.imshow(noisy_test_data[idx].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Predicted output from the autoencoder\n",
    "        predicted_output = model.predict(noisy_test_data[idx].reshape(1, 28, 28, 1))\n",
    "        plt.subplot(3, num_images, 2 * num_images + i + 1)\n",
    "        plt.imshow(predicted_output[0].reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "display_random_images(test_data, noisy_test_data, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njg5iRwn8v8Y"
   },
   "source": [
    "Compute predictions for the entire noisy MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmvzDlVb2vx4"
   },
   "source": [
    "Compute PSNR and SSIM for model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AahPpEjl2vFX"
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "def compute_mean_psnr(test_data, reconstructed_test_data):\n",
    "    # Compute the mean PSNR (Peak Signal-to-Noise Ratio) for a set of image pairs\n",
    "\n",
    "    if len(test_data) != len(noisy_test_data):\n",
    "        raise ValueError(\"Input lists must have the same length\")\n",
    "\n",
    "    psnr_values = []\n",
    "\n",
    "    for original, noisy in zip(test_data, noisy_test_data):\n",
    "        psnr = peak_signal_noise_ratio(original, noisy)\n",
    "        psnr_values.append(psnr)\n",
    "\n",
    "    mean_psnr = np.mean(psnr_values)\n",
    "    return mean_psnr\n",
    "\n",
    "def compute_mean_ssim(test_data, noisy_test_data):\n",
    "    # Compute the mean SSIM (Structural Similarity Index) for a set of image pairs\n",
    "\n",
    "    if len(test_data) != len(noisy_test_data):\n",
    "        raise ValueError(\"Input lists must have the same length\")\n",
    "\n",
    "    ssim_values = []\n",
    "\n",
    "    for original, noisy in zip(test_data, noisy_test_data):\n",
    "        ssim_score = ssim(original, noisy, multichannel=True)\n",
    "        ssim_values.append(ssim_score)\n",
    "\n",
    "    mean_ssim = np.mean(ssim_values)\n",
    "    return mean_ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ubPE6-w7vM2"
   },
   "outputs": [],
   "source": [
    "reconstructed_images = model.predict(noisy_test_data)\n",
    "print(compute_mean_psnr(test_data, reconstructed_images))\n",
    "print(compute_mean_ssim(test_data, reconstructed_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1r9m6jezt8Fj"
   },
   "source": [
    "# Model with CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9aHipb0GHos"
   },
   "source": [
    "## Load the CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-zP2ceouChX"
   },
   "outputs": [],
   "source": [
    "dataset_builder = dlp.data.CIFAR10DatasetBuilder()\n",
    "dataset_builder.preprocess_dataset_simple_ae(0.1)\n",
    "train_data, test_data = dataset_builder.train_x, dataset_builder.test_x\n",
    "noisy_train_data, noisy_test_data = dataset_builder.noisy_train_data, dataset_builder.noisy_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zt_eCJ3ty_DM"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def display_random_images(train_data, noisy_train_data, num_images=8):\n",
    "    fig, axes = plt.subplots(2, num_images, figsize=(16, 4))\n",
    "\n",
    "    for i in range(num_images):\n",
    "        index = random.randint(0, train_data.shape[0] - 1)\n",
    "\n",
    "        # Display a random image from the clean dataset\n",
    "        axes[0, i].imshow(train_data[index])\n",
    "        axes[0, i].set_title(\"Clean\")\n",
    "\n",
    "        # Display the corresponding image from the noisy dataset\n",
    "        axes[1, i].imshow(noisy_train_data[index])\n",
    "        axes[1, i].set_title(\"Noisy\")\n",
    "\n",
    "        # Remove axis labels\n",
    "        axes[0, i].axis('off')\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Display 8 random images from the datasets\n",
    "display_random_images(train_data, noisy_train_data, num_images=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJNsMBZTFLhz"
   },
   "source": [
    "## Istantiate the model for CIFAR10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DAcBZWw2zlh"
   },
   "outputs": [],
   "source": [
    "autoencoder_cifar = dlp.models.SimpleAutoencoder(input_shape=(32, 32, 3))\n",
    "autoencoder_cifar.model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model = autoencoder_cifar.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bE2MTxR2FYCo"
   },
   "source": [
    "# Train the CIFAR10 model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnDhpmjlJEGq"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.saving import load_model\n",
    "\n",
    "model_path = os.path.join(os.getcwd(), 'models', f'{model.name}_cifar_low_noise.keras')\n",
    "\n",
    "if os.path.exists(model_path):\n",
    "  model = load_model(model_path)\n",
    "else:\n",
    "  if not os.path.exists(os.path.join(os.getcwd(), 'models')):\n",
    "    os.mkdir(os.path.join(os.getcwd(), 'models'))\n",
    "\n",
    "  model.fit(\n",
    "      x=noisy_train_data,\n",
    "      y=train_data,\n",
    "      epochs=100,\n",
    "      batch_size=128,\n",
    "      shuffle=True,\n",
    "      validation_data=(noisy_test_data, test_data)\n",
    "  )\n",
    "  autoencoder_cifar.model.save(os.path.join(os.getcwd(), 'models', f'{model.name}_cifar.keras'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnS7Qc0AEzjk"
   },
   "source": [
    "Display some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hquMd2cQBcar"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_random_images(test_data, noisy_test_data, autoencoder, num_images=10):\n",
    "    # Randomly select 10 indices from the test dataset\n",
    "    random_indices = random.sample(range(len(test_data)), num_images)\n",
    "\n",
    "    plt.figure(figsize=(15, 4))\n",
    "\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        # Original clean image\n",
    "        plt.subplot(3, num_images, i + 1)\n",
    "        plt.imshow(test_data[idx])\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Noisy image\n",
    "        plt.subplot(3, num_images, num_images + i + 1)\n",
    "        plt.imshow(noisy_test_data[idx])\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Predicted output from the autoencoder\n",
    "        predicted_output = model.predict(noisy_test_data[idx].reshape(1, 32, 32, 3))\n",
    "        plt.subplot(3, num_images, 2 * num_images + i + 1)\n",
    "        plt.imshow(predicted_output[0])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "display_random_images(test_data, noisy_test_data, model, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEyKILVdEslc"
   },
   "source": [
    "Compute and display the PSNR and SSIM metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nRyB-rB1ETV5"
   },
   "outputs": [],
   "source": [
    "reconstructed_images = model.predict(noisy_test_data)\n",
    "print(compute_mean_psnr(test_data, reconstructed_images))\n",
    "print(compute_mean_ssim(test_data, reconstructed_images))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
